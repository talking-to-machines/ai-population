{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set working directory to project root, if not done already.\n",
    "project_root = Path('/Users/raymondlow/Documents/talking-to-machines/ai-population').resolve()\n",
    "os.chdir(project_root)\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Set __package__ so that relative imports work.\n",
    "__package__ = \"ai_population.analysis\"\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from ai_population.src.market_signals_tiktok import (\n",
    "    perform_tiktok_profile_search,\n",
    "    perform_tiktok_profile_metadata_search,\n",
    "    perform_tiktok_onboarding_interview,\n",
    ")\n",
    "from ai_population.src.utils import (\n",
    "    perform_video_transcription,\n",
    "    extract_llm_responses,\n",
    ")\n",
    "\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "PROJECT_NAME = \"market-signals-tiktok\"\n",
    "START_DATE = \"12-01-2024\"\n",
    "END_DATE = \"06-01-2025\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download profile metadata and posts for ground truth finfluencers and non-finfluencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_tiktok_profile_metadata_search(\n",
    "    project_name=PROJECT_NAME,\n",
    "    input_file_path=\"ground_truth_profile_list.csv\",\n",
    "    output_file_path=\"ground_truth_profile_metadata.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_tiktok_profile_search(\n",
    "    project_name=PROJECT_NAME,\n",
    "    input_file_path=\"ground_truth_profile_list.csv\",\n",
    "    output_file_path=\"ground_truth_profile_posts.csv\",\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and transcribe videos from ground truth finfluencers and non-finfluencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_video_transcription(\n",
    "    project_name=PROJECT_NAME,\n",
    "    video_metadata_file=\"ground_truth_profile_posts.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Onboarding Interview for ground truth finfluencers and non-finfluencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_tiktok_onboarding_interview(\n",
    "    project_name=PROJECT_NAME, \n",
    "    profile_metadata_file=\"ground_truth_profile_metadata.csv\", \n",
    "    video_file=\"ground_truth_profile_posts.csv\", \n",
    "    output_file=\"ground_truth_onboarding_results.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Interview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_llm_responses(text, substring_exclusion_list: list = []) -> pd.Series:\n",
    "#     # Split the text by double newlines to separate different questions\n",
    "#     questions_blocks = text.split(\"\\n\\n\")\n",
    "#     questions_blocks = [\n",
    "#         block\n",
    "#         for block in questions_blocks\n",
    "#         if not any(substring in block for substring in substring_exclusion_list)\n",
    "#     ]  # remove blocks containing stock recommendations\n",
    "\n",
    "#     # Initialize lists to store the extracted data\n",
    "#     questions_list = []\n",
    "#     explanations_list = []\n",
    "#     symbols_list = []\n",
    "#     categories_list = []\n",
    "#     speculations_list = []\n",
    "#     values_list = []\n",
    "#     response_list = []\n",
    "\n",
    "#     # Define regex patterns for each field\n",
    "#     question_pattern = r\"\\*\\*question: (.*?)\\*\\*\"\n",
    "#     explanation_pattern = r\"\\*\\*explanation: (.*?)\\*\\*\"\n",
    "#     symbol_pattern = r\"\\*\\*symbol: (.*?)\\*\\*\"\n",
    "#     category_pattern = r\"\\*\\*category: (.*?)\\*\\*\"\n",
    "#     speculation_pattern = r\"\\*\\*speculation: (.*?)\\*\\*\"\n",
    "#     value_pattern = r\"\\*\\*value: (.*?)\\*\\*\"\n",
    "#     response_pattern = r\"\\*\\*response: (.*?)\\*\\*\"\n",
    "\n",
    "#     # Iterate through each question block and extract the fields\n",
    "#     for block in questions_blocks:\n",
    "#         question = re.search(question_pattern, block, re.DOTALL)\n",
    "#         explanation = re.search(explanation_pattern, block, re.DOTALL)\n",
    "#         symbol = re.search(symbol_pattern, block, re.DOTALL)\n",
    "#         category = re.search(category_pattern, block, re.DOTALL)\n",
    "#         speculation = re.search(speculation_pattern, block, re.DOTALL)\n",
    "#         value = re.search(value_pattern, block, re.DOTALL)\n",
    "#         response = re.search(response_pattern, block, re.DOTALL)\n",
    "\n",
    "#         questions_list.append(question.group(1).replace(\"‚Äù\", \"\") if question else None)\n",
    "#         explanations_list.append(explanation.group(1) if explanation else None)\n",
    "#         symbols_list.append(symbol.group(1) if symbol else None)\n",
    "#         categories_list.append(category.group(1) if category else None)\n",
    "#         speculations_list.append(speculation.group(1) if speculation else None)\n",
    "#         values_list.append(value.group(1) if value else None)\n",
    "#         response_list.append(response.group(1) if response else None)\n",
    "\n",
    "#     # Create a DataFrame\n",
    "#     data = {\n",
    "#         \"question\": questions_list,\n",
    "#         \"explanation\": explanations_list,\n",
    "#         \"symbol\": symbols_list,\n",
    "#         \"category\": categories_list,\n",
    "#         \"speculation\": speculations_list,\n",
    "#         \"value\": values_list,\n",
    "#         \"response\": response_list,\n",
    "#     }\n",
    "#     df = pd.DataFrame(data)\n",
    "\n",
    "#     # Flatten the DataFrame into a single Series\n",
    "#     flattened_series = pd.Series()\n",
    "#     for index, row in df.iterrows():\n",
    "#         question_prefix = row[\"question\"]\n",
    "#         if row[\"explanation\"]:\n",
    "#             flattened_series[f\"{question_prefix} - explanation\"] = row[\"explanation\"]\n",
    "#         if row[\"symbol\"]:\n",
    "#             flattened_series[f\"{question_prefix} - symbol\"] = row[\"symbol\"]\n",
    "#         if row[\"category\"]:\n",
    "#             flattened_series[f\"{question_prefix} - category\"] = row[\"category\"]\n",
    "#         if row[\"speculation\"]:\n",
    "#             flattened_series[f\"{question_prefix} - speculation\"] = row[\"speculation\"]\n",
    "#         if row[\"value\"]:\n",
    "#             flattened_series[f\"{question_prefix} - value\"] = row[\"value\"]\n",
    "#         if row[\"response\"]:\n",
    "#             flattened_series[f\"{question_prefix} - response\"] = row[\"response\"]\n",
    "\n",
    "#     return flattened_series\n",
    "\n",
    "\n",
    "extracted_results = identification_results[\"identification_llm_response\"].apply(extract_llm_responses)\n",
    "identification_results = pd.concat([identification_results, extracted_results], axis=1)\n",
    "identification_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Identification Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df):\n",
    "    # Convert \"Is this a finfluencer? - category\" column to binary values\n",
    "    df['Is this a finfluencer? - category'] = df['Is this a finfluencer? - category'].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    # Ensure there are no NaN values in the columns\n",
    "    df = df.dropna(subset=['Finfluencer', 'Is this a finfluencer? - category'])\n",
    "    \n",
    "    # Extract the true labels and predicted labels\n",
    "    y_true = df['Finfluencer']\n",
    "    y_pred = df['Is this a finfluencer? - category']\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate macro-averaged F1 score\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    # Calculate AUC score\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, macro_f1, auc\n",
    "\n",
    "accuracy, macro_f1, auc = calculate_metrics(identification_results)\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Macro-averaged F1 score: {macro_f1:.5f}')\n",
    "print(f'AUC score: {auc:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market-signals-tiktok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
