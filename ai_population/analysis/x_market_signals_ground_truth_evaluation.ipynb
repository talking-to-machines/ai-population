{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set working directory to project root, if not done already.\n",
    "project_root = Path('/Users/raymondlow/Documents/talking-to-machines/ai-population').resolve()\n",
    "os.chdir(project_root)\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Set __package__ so that relative imports work.\n",
    "__package__ = \"ai_population.analysis\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from ai_population.src.market_signals_x import (\n",
    "    perform_x_profile_search,\n",
    "    perform_x_profile_metadata_search,\n",
    "    perform_x_onboarding_interview,\n",
    ")\n",
    "\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "PROJECT_NAME = \"market-signals-x\"\n",
    "EXECUTION_DATE = \"ground-truth-v2\"\n",
    "# START_DATE = \"2024-12-01\"\n",
    "START_DATE = \"2025-06-13\"\n",
    "END_DATE = \"2025-06-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download profile metadata and posts for ground truth finfluencers and non-finfluencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_x_profile_metadata_search(\n",
    "    project_name=PROJECT_NAME,\n",
    "    execution_date=EXECUTION_DATE,\n",
    "    input_file_path=f\"{EXECUTION_DATE}/ground_truth_profile_list.csv\",\n",
    "    output_file_path=\"ground_truth_profile_metadata.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_x_profile_search(\n",
    "    project_name=PROJECT_NAME,\n",
    "    execution_date=EXECUTION_DATE,\n",
    "    input_file_path=f\"{EXECUTION_DATE}/ground_truth_profile_list.csv\",\n",
    "    output_file_path=\"ground_truth_profile_posts-v2.csv\",\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Onboarding Interview for ground truth finfluencers and non-finfluencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_x_onboarding_interview(\n",
    "    project_name=PROJECT_NAME, \n",
    "    execution_date=EXECUTION_DATE,\n",
    "    profile_metadata_file=\"ground_truth_profile_metadata.csv\", \n",
    "    post_file=\"ground_truth_profile_posts.csv\", \n",
    "    output_file=\"ground_truth_onboarding_results.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Identification Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(results_df: pd.DataFrame, ground_truth_finfluencer: list) -> None:\n",
    "\n",
    "    # Exclude provided examples\n",
    "    results_df = results_df[~results_df['account_id'].isin([\"TheStalwart\",\"AswathDamodaran\",\"LizAnnSonders\"])].reset_index(drop=True)\n",
    "\n",
    "    # Convert \"Is this a finfluencer? - category\" column to binary values\n",
    "    results_df['Is this a finfluencer? - category'] = results_df['Is this a finfluencer? - category'].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    # Ensure there are no NaN values in the columns\n",
    "    results_df = results_df.dropna(subset=['Is this a finfluencer? - category'])\n",
    "    \n",
    "    # Extract the true labels and predicted labels\n",
    "    results_df['Finfluencer'] = [1 if account_id in ground_truth_finfluencer else 0 for account_id in results_df['account_id']]\n",
    "    y_true = results_df['Finfluencer']\n",
    "    y_pred = results_df['Is this a finfluencer? - category']\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate macro-averaged F1 score\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    # Calculate AUC score\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, macro_f1, auc\n",
    "\n",
    "onboarding_results = pd.read_csv(os.path.join(\"ai_population/data\", PROJECT_NAME, EXECUTION_DATE, \"ground_truth_onboarding_results.csv\"))\n",
    "ground_truth = pd.read_csv(os.path.join(\"ai_population/data\", PROJECT_NAME, EXECUTION_DATE, \"ground_truth_profile_list.csv\"))\n",
    "ground_truth_finfluencer = ground_truth[ground_truth[\"finfluencer\"]== \"Yes\"][\"account_id\"].tolist()\n",
    "accuracy, macro_f1, auc = calculate_metrics(onboarding_results, ground_truth_finfluencer)\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Macro-averaged F1 score: {macro_f1:.5f}')\n",
    "print(f'AUC score: {auc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market-signals-tiktok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
