{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Interview Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_file(file_path) -> list:\n",
    "    \"\"\"\n",
    "    Load search terms for market signals or profile list from text file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the text file containing search terms/profiles, one per line.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of search terms/profiles as strings.\n",
    "    \"\"\"\n",
    "    full_file_path = f\"../config/{file_path}\"\n",
    "    with open(full_file_path, \"r\") as file:\n",
    "        return [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identification_results = pd.read_csv(\"../data/market-signals-finfluencer/profile_metadata_post_identification.csv\")\n",
    "print(identification_results.shape)\n",
    "identification_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finfluencer_list = load_text_file(\"market_signals_finfluencer_profiles_finfluencers.txt\")\n",
    "nonfinfluencer_list = load_text_file(\"market_signals_finfluencer_profiles_nonfinfluencers.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identification_results[\"Finfluencer\"] = identification_results[\"profile\"].apply(lambda x: 1 if x in finfluencer_list else 0)\n",
    "print(identification_results.shape)\n",
    "identification_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Interview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_llm_responses(text, substring_exclusion_list: list = []) -> pd.Series:\n",
    "    # Split the text by double newlines to separate different questions\n",
    "    questions_blocks = text.split(\"\\n\\n\")\n",
    "    questions_blocks = [\n",
    "        block\n",
    "        for block in questions_blocks\n",
    "        if not any(substring in block for substring in substring_exclusion_list)\n",
    "    ]  # remove blocks containing stock recommendations\n",
    "\n",
    "    # Initialize lists to store the extracted data\n",
    "    questions_list = []\n",
    "    explanations_list = []\n",
    "    symbols_list = []\n",
    "    categories_list = []\n",
    "    speculations_list = []\n",
    "    values_list = []\n",
    "    response_list = []\n",
    "\n",
    "    # Define regex patterns for each field\n",
    "    question_pattern = r\"\\*\\*question: (.*?)\\*\\*\"\n",
    "    explanation_pattern = r\"\\*\\*explanation: (.*?)\\*\\*\"\n",
    "    symbol_pattern = r\"\\*\\*symbol: (.*?)\\*\\*\"\n",
    "    category_pattern = r\"\\*\\*category: (.*?)\\*\\*\"\n",
    "    speculation_pattern = r\"\\*\\*speculation: (.*?)\\*\\*\"\n",
    "    value_pattern = r\"\\*\\*value: (.*?)\\*\\*\"\n",
    "    response_pattern = r\"\\*\\*response: (.*?)\\*\\*\"\n",
    "\n",
    "    # Iterate through each question block and extract the fields\n",
    "    for block in questions_blocks:\n",
    "        question = re.search(question_pattern, block, re.DOTALL)\n",
    "        explanation = re.search(explanation_pattern, block, re.DOTALL)\n",
    "        symbol = re.search(symbol_pattern, block, re.DOTALL)\n",
    "        category = re.search(category_pattern, block, re.DOTALL)\n",
    "        speculation = re.search(speculation_pattern, block, re.DOTALL)\n",
    "        value = re.search(value_pattern, block, re.DOTALL)\n",
    "        response = re.search(response_pattern, block, re.DOTALL)\n",
    "\n",
    "        questions_list.append(question.group(1).replace(\"‚Äù\", \"\") if question else None)\n",
    "        explanations_list.append(explanation.group(1) if explanation else None)\n",
    "        symbols_list.append(symbol.group(1) if symbol else None)\n",
    "        categories_list.append(category.group(1) if category else None)\n",
    "        speculations_list.append(speculation.group(1) if speculation else None)\n",
    "        values_list.append(value.group(1) if value else None)\n",
    "        response_list.append(response.group(1) if response else None)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    data = {\n",
    "        \"question\": questions_list,\n",
    "        \"explanation\": explanations_list,\n",
    "        \"symbol\": symbols_list,\n",
    "        \"category\": categories_list,\n",
    "        \"speculation\": speculations_list,\n",
    "        \"value\": values_list,\n",
    "        \"response\": response_list,\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Flatten the DataFrame into a single Series\n",
    "    flattened_series = pd.Series()\n",
    "    for index, row in df.iterrows():\n",
    "        question_prefix = row[\"question\"]\n",
    "        if row[\"explanation\"]:\n",
    "            flattened_series[f\"{question_prefix} - explanation\"] = row[\"explanation\"]\n",
    "        if row[\"symbol\"]:\n",
    "            flattened_series[f\"{question_prefix} - symbol\"] = row[\"symbol\"]\n",
    "        if row[\"category\"]:\n",
    "            flattened_series[f\"{question_prefix} - category\"] = row[\"category\"]\n",
    "        if row[\"speculation\"]:\n",
    "            flattened_series[f\"{question_prefix} - speculation\"] = row[\"speculation\"]\n",
    "        if row[\"value\"]:\n",
    "            flattened_series[f\"{question_prefix} - value\"] = row[\"value\"]\n",
    "        if row[\"response\"]:\n",
    "            flattened_series[f\"{question_prefix} - response\"] = row[\"response\"]\n",
    "\n",
    "    return flattened_series\n",
    "\n",
    "\n",
    "extracted_results = identification_results[\"identification_llm_response\"].apply(extract_llm_responses)\n",
    "identification_results = pd.concat([identification_results, extracted_results], axis=1)\n",
    "identification_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Identification Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df):\n",
    "    # Convert \"Is this a finfluencer? - category\" column to binary values\n",
    "    df['Is this a finfluencer? - category'] = df['Is this a finfluencer? - category'].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    # Ensure there are no NaN values in the columns\n",
    "    df = df.dropna(subset=['Finfluencer', 'Is this a finfluencer? - category'])\n",
    "    \n",
    "    # Extract the true labels and predicted labels\n",
    "    y_true = df['Finfluencer']\n",
    "    y_pred = df['Is this a finfluencer? - category']\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate macro-averaged F1 score\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    # Calculate AUC score\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, macro_f1, auc\n",
    "\n",
    "accuracy, macro_f1, auc = calculate_metrics(identification_results)\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(f'Macro-averaged F1 score: {macro_f1:.5f}')\n",
    "print(f'AUC score: {auc:.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market-signals-tiktok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
