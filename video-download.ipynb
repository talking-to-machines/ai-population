{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "import pandas as pd\n",
    "import yt_dlp\n",
    "from openai import OpenAI\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the downloads folder for project if it does not exist\n",
    "PROJECT = \"market-signals\"\n",
    "folder_path = os.path.join(\"downloads\", PROJECT)\n",
    "os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_metadata = pd.read_csv(f\"results/{PROJECT}/video_metadata.csv\")\n",
    "video_metadata.dropna(subset=[\"id\"], inplace=True)\n",
    "video_metadata[\"id\"] = video_metadata[\"id\"].astype(int)\n",
    "video_metadata[\"id\"] = video_metadata[\"id\"].astype(str)\n",
    "video_metadata[\"video_filename\"] = video_metadata.apply(lambda row: f\"{row['id']}.mp4\", axis=1)\n",
    "\n",
    "# Filter out videos that have been downloaded\n",
    "downloaded_videos = [f for f in os.listdir(f\"downloads/{PROJECT}/\") if f.endswith('.mp4')]\n",
    "video_metadata[\"downloaded\"] = video_metadata[\"video_filename\"].apply(lambda x: 1 if x in downloaded_videos else 0)\n",
    "filtered_video_metadata = video_metadata[video_metadata[\"downloaded\"]==0].reset_index(drop=True)\n",
    "filtered_video_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(row):\n",
    "    # The TikTok video link\n",
    "    video_url = row[\"webVideoUrl\"]\n",
    "\n",
    "    # Output file name\n",
    "    output_file = f\"downloads/{PROJECT}/{row['video_filename']}\"\n",
    "\n",
    "    # Options for yt-dlp\n",
    "    ydl_opts = {\n",
    "        \"outtmpl\": output_file,  # Save the video with this file name\n",
    "        \"format\": \"best\",        # Download the best quality available\n",
    "    }\n",
    "\n",
    "    # Download the video\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([video_url])\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred downloading {video_url}:\", str(e))\n",
    "\n",
    "filtered_video_metadata.progress_apply(download_video, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Audio Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()\n",
    "\n",
    "def optimize_audio_file(input_file_path, output_file_path):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_file_path)\n",
    "\n",
    "    # Downsample the audio to 16 kHz and convert to mono\n",
    "    audio = audio.set_frame_rate(16000).set_channels(1)\n",
    "\n",
    "    # Export the optimized audio file\n",
    "    audio.export(output_file_path, format=\"wav\")\n",
    "\n",
    "def transcribe_videos(row):\n",
    "    input_file_path = f\"downloads/{PROJECT}/{row['video_filename']}\"\n",
    "    optimized_file_path = f\"downloads/{PROJECT}/optimized_{row['video_filename']}\"\n",
    "\n",
    "    try:\n",
    "        with open(input_file_path, \"rb\") as audio_file:\n",
    "            transcription = openai_client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\", \n",
    "                file=audio_file, \n",
    "                response_format=\"text\"\n",
    "            )\n",
    "        return transcription\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        if e.status_code == 413:\n",
    "            print(f\"Error: File {row['video_filename']} is too large to process. Optimizing the audio file...\")\n",
    "            # Optimize the audio file\n",
    "            optimize_audio_file(input_file_path, optimized_file_path)\n",
    "            try:\n",
    "                with open(optimized_file_path, \"rb\") as audio_file:\n",
    "                    transcription = openai_client.audio.transcriptions.create(\n",
    "                        model=\"whisper-1\", \n",
    "                        file=audio_file, \n",
    "                        response_format=\"text\"\n",
    "                    )\n",
    "                return transcription\n",
    "            except Exception as e:\n",
    "                print(f\"Error: File {optimized_file_path} is still too large after optimisation: {e}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Error encountered when transcribing {row['video_filename']}: {e}\")\n",
    "            return None\n",
    "\n",
    "video_metadata[\"video_transcription\"] = video_metadata.progress_apply(transcribe_videos, axis=1)\n",
    "video_metadata.to_csv(f\"results/{PROJECT}/video_metadata_with_transcript.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-transcript",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
